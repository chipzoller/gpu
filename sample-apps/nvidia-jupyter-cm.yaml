# change the nruns param on L193 to a higher value to extend the GPU runtime
apiVersion: v1
kind: ConfigMap
metadata:
  name: notebook
  namespace: gpu-testing
data:
  notebook.ipynb: |-
    {
    "cells": [
      {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"https://developer.download.nvidia.com/tesla/notebook_assets/nv_logo_torch_trt_resnet_notebook.png\" style=\"width: 90px; float: right;\">\n",
        "\n",
        "# Torch-TensorRT Getting Started - ResNet 50"
      ]
      },
      {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!nvidia-smi\n",
        "!pip install ipywidgets torch torchvision matplotlib --trusted-host pypi.org --trusted-host pypi.python.org --trusted-host=files.pythonhosted.org"
      ]
      },
      {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "torch.hub._validate_not_a_forked_repo=lambda a,b,c: True\n",
        "\n",
        "resnet50_model = torch.hub.load('pytorch/vision:v0.19.0', 'resnet50', weights=\"IMAGENET1K_V2\")\n",
        "resnet50_model.eval()"
      ]
      },
      {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!mkdir -p /data\n",
        "!wget  -O /data/img0.JPG \"https://d17fnq9dkz9hgj.cloudfront.net/breed-uploads/2018/08/siberian-husky-detail.jpg?bust=1535566590&width=630\"\n",
        "!wget  -O /data/img1.JPG \"https://www.hakaimagazine.com/wp-content/uploads/header-gulf-birds.jpg\"\n",
        "!wget  -O /data/img2.JPG \"https://www.artis.nl/media/filer_public_thumbnails/filer_public/00/f1/00f1b6db-fbed-4fef-9ab0-84e944ff11f8/chimpansee_amber_r_1920x1080.jpg__1920x1080_q85_subject_location-923%2C365_subsampling-2.jpg\"\n",
        "!wget  -O /data/img3.JPG \"https://www.familyhandyman.com/wp-content/uploads/2018/09/How-to-Avoid-Snakes-Slithering-Up-Your-Toilet-shutterstock_780480850.jpg\"\n",
        "\n",
        "!wget  -O /data/imagenet_class_index.json \"https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\""
      ]
      },
      {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import json \n",
        "\n",
        "fig, axes = plt.subplots(nrows=2, ncols=2)\n",
        "\n",
        "for i in range(4):\n",
        "    img_path = '/data/img%d.JPG'%i\n",
        "    img = Image.open(img_path)\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    input_tensor = preprocess(img)      \n",
        "    plt.subplot(2,2,i+1)\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "\n",
        "# loading labels    \n",
        "with open(\"/data/imagenet_class_index.json\") as json_file: \n",
        "    d = json.load(json_file)"
      ]
      },
      {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import torch.backends.cudnn as cudnn\n",
        "cudnn.benchmark = True\n",
        "\n",
        "def rn50_preprocess():\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    return preprocess\n",
        "\n",
        "# decode the results into ([predicted class, description], probability)\n",
        "def predict(img_path, model):\n",
        "    img = Image.open(img_path)\n",
        "    preprocess = rn50_preprocess()\n",
        "    input_tensor = preprocess(img)\n",
        "    input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
        "    \n",
        "    # move the input and model to GPU for speed if available\n",
        "    if torch.cuda.is_available():\n",
        "        input_batch = input_batch.to('cuda')\n",
        "        model.to('cuda')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(input_batch)\n",
        "        # Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes\n",
        "        sm_output = torch.nn.functional.softmax(output[0], dim=0)\n",
        "        \n",
        "    ind = torch.argmax(sm_output)\n",
        "    return d[str(ind.item())], sm_output[ind] #([predicted class, description], probability)\n",
        "\n",
        "def benchmark(model, input_shape=(1024, 1, 224, 224), dtype='fp32', nwarmup=50, nruns=10000):\n",
        "    input_data = torch.randn(input_shape)\n",
        "    input_data = input_data.to(\"cuda\")\n",
        "    if dtype=='fp16':\n",
        "        input_data = input_data.half()\n",
        "        \n",
        "    print(\"Warm up ...\")\n",
        "    with torch.no_grad():\n",
        "        for _ in range(nwarmup):\n",
        "            features = model(input_data)\n",
        "    torch.cuda.synchronize()\n",
        "    print(\"Start timing ...\")\n",
        "    timings = []\n",
        "    with torch.no_grad():\n",
        "        for i in range(1, nruns+1):\n",
        "            start_time = time.time()\n",
        "            features = model(input_data)\n",
        "            torch.cuda.synchronize()\n",
        "            end_time = time.time()\n",
        "            timings.append(end_time - start_time)\n",
        "            if i%10==0:\n",
        "                print('Iteration %d/%d, ave batch time %.2f ms'%(i, nruns, np.mean(timings)*1000))\n",
        "\n",
        "    print(\"Input shape:\", input_data.size())\n",
        "    print(\"Output features size:\", features.size())\n",
        "    print('Average batch time: %.2f ms'%(np.mean(timings)*1000))"
      ]
      },
      {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(4):\n",
        "    img_path = '/data/img%d.JPG'%i\n",
        "    img = Image.open(img_path)\n",
        "    \n",
        "    pred, prob = predict(img_path, resnet50_model)\n",
        "    print('{} - Predicted: {}, Probablility: {}'.format(img_path, pred, prob))\n",
        "\n",
        "    plt.subplot(2,2,i+1)\n",
        "    plt.imshow(img);\n",
        "    plt.axis('off');\n",
        "    plt.title(pred[1])"
      ]
      },
      {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Model benchmark without Torch-TensorRT\n",
        "model = resnet50_model.eval().to(\"cuda\")\n",
        "benchmark(model, input_shape=(128, 3, 224, 224), nruns=1000)"
      ]
      },
      {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!sleep infinity"
      ]
      }
    ],
    "metadata": {
      "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
      },
      "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
      }
    },
    "nbformat": 4,
    "nbformat_minor": 4
    }
